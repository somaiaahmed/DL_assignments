{"cells":[{"cell_type":"code","source":["import numpy as np\n","from random import Random\n","from math import ceil\n"],"metadata":{"id":"ARKXWlennaCn","executionInfo":{"status":"ok","timestamp":1718030870657,"user_tz":-180,"elapsed":1,"user":{"displayName":"Mostafa ali","userId":"05915003440821628655"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXaH1KnC4rTK"},"source":["# Assignment 2"]},{"cell_type":"markdown","metadata":{"id":"47W2WRSI4rTK"},"source":["The living area of an apartment influences its selling price.\n","Assume this relationship can be modeled by the following equation\n","\n","Y = aX<sup>5</sup> + bX<sup>4</sup> + cX<sup>3</sup> + dX<sup>2</sup> + eX + f\n","\n","Where the selling price is Y and X is the are of an appartment,\n","\n","Let the loss function be the mean square error.\n","Use SGD to find optimal values of the hyper paramters."]},{"cell_type":"markdown","source":["We use the model (function defines the problem) $y = f(x)$ the selling price here is y and x is the area. as the model has unkown parameters (a, b, c, d,e ,f) the task is to derive these paramters using the known data (y,x)"],"metadata":{"id":"BR5IuJWdcTW3"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"cc5Ymg0w4rTK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f17d7e09-0d20-4e68-8e5e-8aa6a74d19fb","executionInfo":{"status":"ok","timestamp":1718030896412,"user_tz":-180,"elapsed":302,"user":{"displayName":"Mostafa ali","userId":"05915003440821628655"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(100, 6) (100, 1)\n"]}],"source":["SEED = 5\n","def generate_pnts(N=100):\n","    np.random.seed = 5\n","    x, y = np.array([]), np.array([])\n","    x = np.random.rand(N,6) #the dimension of the data x is (n,6)\n","    y = np.random.rand(N,1)  #the dimension of the data x is (n,1)\n","\n","    return x, y\n","data_x, data_y = generate_pnts()\n","\n","print(data_x.shape, data_y.shape)"]},{"cell_type":"markdown","source":["Knowing that the the model is $y = ax^5 +bx^4 + cx^3 +dx^2+ex + f$ <br>\n","it's can be written in teh vector form : $Y = P . X^T $ P is the parameters vector (1,6) and X is the data matrix (N,6) <br>\n","the answer is the Y vector predicted values (1,N)"],"metadata":{"id":"v4P-CC4Ik6Cy"}},{"cell_type":"code","source":["def predict(data_x, params):\n","    # data_X, params and yhat should be numpy arrays\n","    # Y = aX^5 + bX^4 + cX^3 + dX^2 + eX + f\n","    data_x = np.array(data_x)\n","    yhat = np.dot(params, data_x.transpose()) #(1,6) dot (6,N) = (1,N)\n","\n","    return yhat"],"metadata":{"id":"Sea3TNuAVfG8","executionInfo":{"status":"ok","timestamp":1718031937967,"user_tz":-180,"elapsed":1,"user":{"displayName":"Mostafa ali","userId":"05915003440821628655"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["params = np.array([[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]) #shape of [[X]] is (X,1) but shape of [X] is (X,)\n","\n","yhat = predict(data_x, params)\n","print(yhat.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-PTvy81b8wq","outputId":"4455ae29-5180-4e11-a74c-e354ea7ae704","executionInfo":{"status":"ok","timestamp":1718031938355,"user_tz":-180,"elapsed":2,"user":{"displayName":"Mostafa ali","userId":"05915003440821628655"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 100)\n"]}]},{"cell_type":"markdown","source":["Using the Mean square error:\n","- Mean squared Error:  $ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $\n","<br>"],"metadata":{"id":"vaKQ73dutykT"}},{"cell_type":"code","source":["def loss(data_x, params, data_y):\n","      '''\n","      data_x shape is (N,6)\n","      data_y shape is (N,1)\n","      yhat shape is (N,1) after transposing\n","      param shape should be (1,6)\n","      '''\n","      yhat = predict(data_x, params).transpose() #shape of yhat after transposing is (N,1)\n","      loss = (1 / len(data_y)) * np.sum((yhat - data_y) ** 2) # ( (N,1) - (N,1) )^2 -> (N,1) the summation then is one value\n","      return loss\n","print(loss(data_x, params, data_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yy8nA09bcCBg","outputId":"ce061193-1fcc-4e83-a56d-c0417974c7fd","executionInfo":{"status":"ok","timestamp":1718031940373,"user_tz":-180,"elapsed":471,"user":{"displayName":"Mostafa ali","userId":"05915003440821628655"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["6.8191269002534005\n"]}]},{"cell_type":"markdown","source":["We will use the closed form method to calculate the  gradient as the gradient of the MSE  with respect to its parameters is : $$\\nabla_{\\theta} J(\\theta) = \\begin{bmatrix}\n","\\frac{\\partial J}{\\partial \\theta_1} \\\\\n","\\frac{\\partial J}{\\partial \\theta_2} \\\\\n","\\vdots \\\\\n","\\frac{\\partial J}{\\partial \\theta_m}\n","\\end{bmatrix}$$\n","\n","Or simply can express it as $$\\frac{\\partial \\, \\text{MSE}}{\\partial {a}} =   -x^5 .2(y_i - \\hat{y}_i)$$\n","\n","apply the same principle for the rest prarmeters:\n","Apply the vector form:\n","$$\\frac{\\partial \\, \\text{L}}{\\partial {P}} =   (Y- \\hat{Y}_i)^{T}_{(1,N)}.  X_{(N,6)} . $$\n"],"metadata":{"id":"Jeq1dwqvvqFx"}},{"cell_type":"code","source":["def calc_grad(params, data_x, data_y):\n","    # write code here that calculates the gradient with respect to\n","    # each parameter\n","    # return one numpy array with the gradients\n","    data_x = np.array(data_x)\n","\n","    yhat = predict(data_x, params).transpose()#shape of yhat after transposing is (N,1)\n","    loss_grad = (-2 * (data_y - yhat)) / len(data_y) #(N,1) - (N,1) -> (N,1)\n","    grad = np.dot(loss_grad.transpose(),data_x) #(N,1)^T dot (N,6) -> (1,6)\n","\n","    return grad\n"],"metadata":{"id":"0_z0y_c4cFHz","executionInfo":{"status":"ok","timestamp":1718031946195,"user_tz":-180,"elapsed":2,"user":{"displayName":"Mostafa ali","userId":"05915003440821628655"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["We will divide the data into patches and loop over them to train the model. The update will be in vector form as wee discussed\n","$$P_{(1,6) }- \\frac{\\partial \\, \\text{L}}{\\partial {P}}_{(1,6)}= P_{new(1,6) }$$\n","\n","---\n","\n"],"metadata":{"id":"rJLyenZWuH7I"}},{"cell_type":"code","execution_count":18,"metadata":{"editable":true,"id":"XMpdIHzo4rTL","tags":["solution"],"executionInfo":{"status":"ok","timestamp":1718031948717,"user_tz":-180,"elapsed":1,"user":{"displayName":"Mostafa ali","userId":"05915003440821628655"}}},"outputs":[],"source":["def train(data_x, data_y, EPOCHS = 100):\n","    # initialization\n","    params = np.array([[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]) #shape of params must be (1,6)\n","    DELTA = 0.01\n","    BATCH_SIZE = 4\n","    indices = [i for i in range(len(data_x))]\n","    sampler = Random(x = 5)\n","\n","    NUM_BATCHES = ceil(len(data_x)/BATCH_SIZE)\n","\n","    batches_losses = []\n","    ##############################################\n","\n","    # Optimization loop of SGD\n","    for _ in range(EPOCHS):\n","      sampler.shuffle(indices)\n","\n","      batches_count = ceil(len(data_y) / BATCH_SIZE)\n","\n","      for batch_index in range(batches_count): #looping over batches\n","          batch_indices = indices[batch_index * BATCH_SIZE: (batch_index + 1) * BATCH_SIZE]\n","          batch_x = [data_x[i] for i in batch_indices]\n","          batch_y = [data_y[i] for i in batch_indices]\n","\n","          grad = calc_grad(params, data_x=batch_x, data_y=batch_y)\n","          params -= DELTA * grad #update the params  in vector form (1,6) - (1,6) -> (1,6)\n","\n","          batches_losses.append(loss(data_x, params, data_y))\n","      return params, batches_losses\n","\n","    # Don't change the return\n"]},{"cell_type":"code","source":["print(train(data_x, data_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DzpcVWn9UC1N","outputId":"457ae6c7-0911-47b8-92c2-ac259f3b2da7","executionInfo":{"status":"ok","timestamp":1718031949486,"user_tz":-180,"elapsed":395,"user":{"displayName":"Mostafa ali","userId":"05915003440821628655"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["(array([[0.53354342, 0.5474588 , 0.52700217, 0.53714744, 0.50113882,\n","        0.5605846 ]]), [6.280311280125159, 5.933807619628513, 5.554135059461035, 5.298763231678374, 5.163589771515892, 4.925352447324985, 4.777890803874532, 4.368684298535331, 4.015190991335352, 3.6900656454812686, 3.495497790345883, 3.278731960972186, 3.095262153674454, 2.910760678974012, 2.688826457344556, 2.4897371527076944, 2.3504197926520884, 2.217477057530699, 2.0895591159745335, 2.0098174251599756, 1.8589227642870796, 1.7426183186984225, 1.652796720279795, 1.5338886872706263, 1.4481193035337512])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Z8u0HpwIrtd8"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}